{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Natural Language Processing](https://www.kaggle.com/learn/natural-language-processing) course.  You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/text-classification).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Natural Language Classification\n\nYou did a great such a great job for DeFalco's restaurant in the previous exercise that the chef has hired you for a new project.\n\nThe restaurant's menu includes an email address where visitors can give feedback about their food. \n\nThe manager wants you to create a tool that automatically sends him all the negative reviews so he can fix them, while automatically sending all the positive reviews to the owner, so the manager can ask for a raise. \n\nYou will first build a model to distinguish positive reviews from negative reviews using Yelp reviews because these reviews include a rating with each review. Your data consists of the text body of each review along with the star rating. Ratings with 1-2 stars count as \"negative\", and ratings with 4-5 stars are \"positive\". Ratings with 3 stars are \"neutral\" and have been dropped from the data.\n\nLet's get started. First, run the next code cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# Set up code checking\n!pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.nlp.ex2 import *\nprint(\"\\nSetup complete\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Evaluate the Approach\n\nIs there anything about this approach that concerns you? After you've thought about it, run the function below to see one point of view."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nstep_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Review Data and Create the model\n\nMoving forward with your plan, you'll need to load the data. Here's some basic code to load data and split it into a training and validation set. Run this code."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(csv_file, split=0.9):\n    data = pd.read_csv(csv_file)\n    \n    # Shuffle data\n    train_data = data.sample(frac=1, random_state=7)\n    \n    texts = train_data.text.values\n    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n              for y in train_data.sentiment.values]\n    split = int(len(train_data) * split)\n    \n    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n    \n    return texts[:split], train_labels, texts[split:], val_labels\n\ntrain_texts, train_labels, val_texts, val_labels = load_data('../input/nlp-course/yelp_ratings.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You will use this training data to build a model. The code to build the model is the same as what you saw in the tutorial. So that is copied below for you.\n\nBut because your data is different, there are **two lines in the modeling code cell that you'll need to change.** Can you figure out what they are? \n\nFirst, run the cell below to look at a couple elements from your training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Texts from training data\\n------')\nprint(train_texts[:2])\nprint('\\nLabels from training data\\n------')\nprint(train_labels[:2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, having seen this data, find the two lines that need to be changed."},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n              \"textcat\",\n              config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\n\n# Add labels to text classifier\ntextcat.add_label(\"NEGATIVE\")\ntextcat.add_label(\"POSITIVE\")\n\n# Check your answer\nstep_2.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lines below will give you a hint or solution code\nstep_2.hint()\nstep_2.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3: Train Function\n\nImplement a function `train` that updates a model with training data. Most of this is general data munging, which we've filled in for you. Just add the one line of code necessary to update your model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train_data)\n    \n    batches = minibatch(train_data, size=8)\n    for batch in batches:\n        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n        # Split batch into texts and labels\n        texts, labels = zip(*batch)\n        \n        # Update model with texts and labels\n        model.update(texts, labels, sgd = optimizer, losses = losses)\n        \n    return losses\n\n# Check your answer\nstep_3.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lines below will give you a hint or solution code\nstep_3.hint()\nstep_3.solution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can try this slightly trained model on some example text and look at the probabilities assigned to each label."},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"This tea cup was full of holes. Do not recommend.\"\ndoc = nlp(text)\nprint(doc.cats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These probabilities look reasonable. Now you should turn them into an actual prediction.\n\n# Step 4: Making Predictions\n\nImplement a function `predict` that predicts the sentiment of text examples. \n- First, tokenize the texts using `nlp.tokenizer()`. \n- Then, pass those docs to the TextCategorizer which you can get from `nlp.get_pipe()`. \n- Use the `textcat.predict()` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(nlp, texts): \n    # Use the model's tokenizer to tokenize each input text\n    docs = [nlp.tokenizer(text) for text in texts]\n    \n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n    \n    # From the scores, find the class with the highest score/probability\n    predicted_class = scores.argmax(axis = 1)\n    \n    return predicted_class\n\n# Check your answer\nstep_4.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lines below will give you a hint or solution code\nstep_4.hint()\nstep_4.solution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like your model is working well after going through the data just once. However you need to calculate some metric for the model's performance on the hold-out validation data.\n\n# Step 5: Evaluate The Model\n\nImplement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n\nFirst, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model (using your predict method)\n    predicted_class = predict(model, texts)\n    \n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    true_class = [int(each['cats']['POSITIVE']) for each in labels]\n    \n    # A boolean or int array indicating correct predictions\n    correct_predictions = predicted_class == true_class\n    \n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = correct_predictions.mean()\n    \n    return accuracy\n\nstep_5.check()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lines below will give you a hint or solution code\nstep_5.hint()\nstep_5.solution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the functions implemented, you can train and evaluate in a loop."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This may take a while to run!\nn_iters = 5\nfor i in range(n_iters):\n    losses = train(nlp, train_data, optimizer)\n    accuracy = evaluate(nlp, val_texts, val_labels)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 6: Keep Improving\n\nYou've built the necessary components to train a text classifier with spaCy. What could you do further to optimize the model?\n\nRun the next line to check your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nstep_6.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keep Going\n\nThe next step is a big one. See how you can **[represent tokens as vectors that describe their meaning](https://www.kaggle.com/matleonard/word-vectors)**, and plug those into your machine learning models."},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161466) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}